---
title: "Bayesian mixed models with brms | session 2"
author: Jens Roeser 
date: 'Last updated: `r Sys.Date()`'
output: 
  ioslides_presentation:
#  revealjs::revealjs_presentation:
    theme: simplex
    highlight: zenburn
    incremental: true
    transition: slower
    widescreen: true
    smaller: true

bibliography: ["references.bib"]
csl: apa.csl
link-citations: no

---

```{r setup, include=FALSE}
library(citr)
library(tidyverse)
library(magrittr)
library(lme4)
library(brms)
library(ggthemes)
library(kableExtra)
library(knitr)
library(readxl)
library(extrafont)
library(broom)
library(tidybayes)
library(janitor)
library(patchwork)
library(mixtools)
source("../scripts/functions.R")
options("kableExtra.html.bsTable" = T)
knitr::opts_chunk$set(echo = FALSE,
                      comment=NA, 
                      warning = FALSE,
                      message =FALSE)
theme_set(theme_few(base_size = 13))
data <- read_csv("../data/sentence_transitions.csv")
```



## Outline

>- The notorious Bayes Factor   
>- Families of distributions / models of keystroke data
>- Model comparison (leave-one-out cross-validation)
>- Summary / reading recommendations


# The notorious Bayes Factor | chapter 7.6 in @lee2014bayesian


## Bayes Factor

<div style="float: left;width: 70%;">

>- *p*-values have two possible outcomes: 
>1. reject the null (i.e. $p<0.05$)
>2. inconclusive (i.e. $p>0.05$ -- go back to start)

>- BFs have a continuum of three possible outcomes [@dienes2014using; @dienes2016bayes; @dienes2018four]:
>1. Reject the null / alternative hypothesis
>2. Inconclusive (get more data!)
>3. Accept the null / alternative hypothesis


</div>


<div style="float: right;width: 20%;">
![](pics/bfs.png){width="105%"}
</div>


## Bayes Factor 


<div style="float: right;width: 75%;">

- How much more probable is one model (hypothesis) over the other?
- How convinced should we be about the evidence for our hypothesis $H_1$ as opposed to, say, a null hypothesis $H_0$?
- Savage-Dickey density ratio for "nested models" [@jeffreys1961theory; @dickey1970weighted].
- Height of the posterior density at zero compared to the height of the prior density at zero.
- **Nested models:** 
  - $H_0$ is nested in $H_1$ because in $H_0$ the parameter of interest is fixed ($\beta=0$) but is free to vary in $H_1$ ($\beta\neq0$)
  - $H_0$ can be obtained from $H_1$ by fixing parameter of interest.
</div>



## Bayes Factor


<div style="float: left; width: 25%;">

>- If you care about the alternative hypothesis:

$$
\text{BF} = \frac{p(H_1 \mid y)}{p(H_0 \mid y)} 
$$
</div>

<div style="float: right;width: 75%;">

>- How much more probable is one model (hypothesis) over the other?
>- How convinced should we be about the evidence for our hypothesis as opposed to, say, a null hypothesis?
>- Savage-Dickey density ratio for "nested models" [@jeffreys1961theory; @dickey1970weighted].
>- Height of the posterior density at zero compared to the height of the prior density at zero.
- **Nested models:** 
  - $H_0$ is nested in $H_1$ because in $H_0$ the parameter of interest is fixed ($\beta=0$) but is free to vary in $H_1$ ($\beta\neq0$)
  - $H_0$ can be obtained from $H_1$ by fixing parameter of interest.

</div>






## Bayes Factor: Savage-Dickey density ratio

<div style="float: left;width: 25%;">

$$
\text{BF} = \frac{\text{prior}}{\text{posterior}}
$$


- Posterior: $N(2.5, 1)$
- Prior: $N(0,10)$


</div>

<div style="float: right;width: 60%;">


```{r fig.width=5}
pd <- tibble(x = seq(-5, 5, by = .1),
             Prior = dnorm(x, 0, 10),
             Posterior = dnorm(x, 2.5, 1)) %>%
  pivot_longer(Prior:Posterior)

data_at_zero <- filter(pd, x == 0)
pr <- filter(data_at_zero, name == "Prior") %>% pull(value)
po <- filter(data_at_zero, name == "Posterior") %>% pull(value)

ggplot(pd, aes(x = x, y = value, colour = name)) +
  geom_line() +
  geom_point(data = data_at_zero, aes(x = x, y = value), 
             colour = "black", size = 2) +
  geom_label(data = data_at_zero, aes(x = x, y = value + .02, label = round(value, 3)), 
             colour = "black", size = 3) +
  scale_color_colorblind("") +
  labs(y = "density", x = bquote(hat(beta)), subtitle = bquote("BF"==.(round(pr/po,2)))) +
  theme(legend.position = c(0.25,.9),
        legend.direction = "horizontal")
```
</div>


## Bayes Factor: Savage-Dickey density ratio

<div style="float: left;width: 25%;">

$$
\text{BF} = \frac{\text{prior}}{\text{posterior}}
$$


>- Posterior: $N(2.5, 1)$
>- Prior: $N(0,5)$



</div>

<div style="float: right;width: 60%;">


```{r fig.width=5}
pd <- tibble(x = seq(-5, 5, by = .1),
             Prior = dnorm(x, 0, 5),
             Posterior = dnorm(x, 2.5, 1)) %>%
  pivot_longer(Prior:Posterior)

data_at_zero <- filter(pd, x == 0)
pr <- filter(data_at_zero, name == "Prior") %>% pull(value)
po <- filter(data_at_zero, name == "Posterior") %>% pull(value)

ggplot(pd, aes(x = x, y = value, colour = name)) +
  geom_line() +
  geom_point(data = data_at_zero, aes(x = x, y = value), 
             colour = "black", size = 2) +
  geom_label(data = data_at_zero, aes(x = x, y = value + .02, label = round(value, 3)), 
             colour = "black", size = 3) +
  scale_color_colorblind("") +
  labs(y = "density", x = bquote(hat(beta)), subtitle = bquote("BF"==.(round(pr/po,2)))) +
  theme(legend.position = c(0.25,.9),
        legend.direction = "horizontal")
```
</div>


## Bayes Factor: Savage-Dickey density ratio

<div style="float: left;width: 25%;">

$$
\text{BF} = \frac{\text{prior}}{\text{posterior}}
$$


>- Posterior: $N(2.5, 1)$
>- Prior: $N(0,2.5)$



</div>

<div style="float: right;width: 60%;">


```{r fig.width=5}
pd <- tibble(x = seq(-5, 5, by = .1),
             Prior = dnorm(x, 0, 2.5),
             Posterior = dnorm(x, 2.5, 1)) %>%
  pivot_longer(Prior:Posterior)

data_at_zero <- filter(pd, x == 0)
pr <- filter(data_at_zero, name == "Prior") %>% pull(value)
po <- filter(data_at_zero, name == "Posterior") %>% pull(value)

ggplot(pd, aes(x = x, y = value, colour = name)) +
  geom_line() +
  geom_point(data = data_at_zero, aes(x = x, y = value), 
             colour = "black", size = 2) +
  geom_label(data = data_at_zero, aes(x = x, y = value + .02, label = round(value, 3)), 
             colour = "black", size = 3) +
  scale_color_colorblind("") +
  labs(y = "density", x = bquote(hat(beta)), subtitle = bquote("BF"==.(round(pr/po,2)))) +
  theme(legend.position = c(0.25,.9),
        legend.direction = "horizontal")
```
</div>


## Bayes Factor: Savage-Dickey density ratio

<div style="float: left;width: 25%;">

$$
\text{BF} = \frac{\text{prior}}{\text{posterior}}
$$



>- Posterior: $N(2.5, 1)$
>- Prior: $N(0,1)$



</div>

<div style="float: right;width: 60%;">


```{r fig.width=5}
pd <- tibble(x = seq(-5, 5, by = .1),
             Prior = dnorm(x, 0, 1.5),
             Posterior = dnorm(x, 2.5, 1)) %>%
  pivot_longer(Prior:Posterior)

data_at_zero <- filter(pd, x == 0)
pr <- filter(data_at_zero, name == "Prior") %>% pull(value)
po <- filter(data_at_zero, name == "Posterior") %>% pull(value)

ggplot(pd, aes(x = x, y = value, colour = name)) +
  geom_line() +
  geom_point(data = data_at_zero, aes(x = x, y = value), 
             colour = "black", size = 2) +
  geom_label(data = data_at_zero, aes(x = x, y = value + .02, label = round(value, 3)), 
             colour = "black", size = 3) +
  scale_color_colorblind("") +
  labs(y = "density", x = bquote(hat(beta)), subtitle = bquote("BF"==.(round(pr/po,2)))) +
  theme(legend.position = c(0.25,.9),
        legend.direction = "horizontal")
```
</div>


## Bayes Factor

```{r eval = F, echo = T}
prior <- set_prior("normal(0, 1)", class = "b")
```


```{r eval = F, echo = T}
fit <- brm(model, 
           data = data, 
           prior = prior, 
           sample_prior = TRUE)
```

- Flat priors are okay (but generally not recommended) defaults if both $H_0$ and $H_1$ are plausible.
- More informative priors such as $N(0,1)$ give more weight to $H_0$.
- Given such a prior, a posterior that favours $H_1$ would be more convincing: BFs capture this.
- Regularizing (skeptical) priors prevent the model to get overexcited by the sample [his words: @mcelreath2016statistical].
- `sample_prior = TRUE` to store the priors that that model used.


## Bayes Factor with `hypothesis()`


```{r echo = T}
# Load the model
brms_sim <- readRDS("../stanout/brms_sim_sample_prior.rda")
```


```{r echo = T}
# Test whether the posterior supports H0
hypothesis(brms_sim, "conditionb = 0")
```

>- Explore `hypothesis()` in the exercise.



## Exercise: priors and Bayes Factors

>- Replace the `---` correctly and run the code.
>- Check out how to calculate a BF if you didn't store the prior: `bayes_factor.R`
>- Rerun Bayesian model from last session with `sample_prior = TRUE` and check your the `hypothesis` function: `brms_sim_sample_prior.R`







# Families of distributions

## Families of distributions 

\

>"Models are devices that connect theories to data.  A model is an instantiation of a theory [...]" [@rouder2016interplay p. 2] 

\


- Our models describe how we understand reality.
- Model allows us to describe reality qualitatively (with their parameters) and quantitatively (parameter value estimates, e.g., mean keystroke interval).
- Interpretation of parameters depends on data-modeling context.
- At minimum, distribution families (probability models) depend on data type.
- This isn't all; there are many distribution families for modeling skewed continuous data.   
- Keystroke intervals are skewed even when log scaled: this skew is important!


## Families of distributions (some important ones)

>- **Gaussian**: data come from normal distribution (last session)

```{r eval=F, echo=T}
fit <- brm(outcome ~ predictor + (1|participant), data = data, family = gaussian())
```


## Families of distributions (some important ones)

>- **Gaussian**: data come from normal distribution (last session)
>- **Bernoulli**: binomial outcomes (yes / no; correct / incorrect)

```{r eval=F, echo=T}
fit <- brm(outcome ~ predictor + (1|participant), data = data, family = bernoulli())
```

## Families of distributions (some important ones)

>- **Gaussian**: data come from normal distribution (last session)
>- **Bernoulli**: binomial outcomes (yes / no; correct / incorrect)
>- **Poisson**: count data (number of words / mistakes)


```{r eval=F, echo=T}
fit <- brm(outcome ~ predictor + (1|participant), data = data, family = poisson())
```

## Families of distributions (some important ones)

>- **Gaussian**: data come from normal distribution (last session)
>- **Bernoulli**: binomial outcomes (yes / no; correct / incorrect)
>- **Poisson**: count data (number of words / mistakes)
>- **Zero-inflated Poisson**: count data with lots of zeros (number of typos per word)


```{r eval=F, echo=T}
fit <- brm(outcome ~ predictor + (1|participant), data = data, family = zero_inflated_poisson())
```


## Families of distributions (some important ones)

>- **Gaussian**: data come from normal distribution (last session)
>- **Bernoulli**: binomial outcomes (yes / no; correct / incorrect)
>- **Poisson**: count data (number of words / mistakes)
>- **Zero-inflated Poisson**: count data with lots of zeros (number of typos per word)
>- Families for ordinal (ordered) data [@burkner2019ordinal] (Likert scales)


```{r eval=F, echo=T}
fit <- brm(outcome ~ predictor + (1|participant), data = data, family = cumulative())# or acat, sratio
```


## Families of distributions (some important ones)

>- **Gaussian**: data come from normal distribution (last session)
>- **Bernoulli**: binomial outcomes (yes / no; correct / incorrect)
>- **Poisson**: count data (number of words / mistakes)
>- **Zero-inflated Poisson**: count data with lots of zeros (number of typos per word)
>- Families for ordinal (ordered) data [@burkner2019ordinal] (Likert scales)
>- **Log-Normal**: zero bound data with positive skew; also skewed / shifted (log)-Normal, Wiener Diffusion models etc. [for RT data; @matzke2009psychological]


```{r eval=F, echo=T}
fit <- brm(outcome ~ predictor + (1|participant), data = data, family = lognormal())
```


## Families of distributions (some important ones)

>- **Gaussian**: data come from normal distribution (last session)
>- **Bernoulli**: binomial outcomes (yes / no; correct / incorrect)
>- **Poisson**: count data (number of words / mistakes)
>- **Zero-inflated Poisson**: count data with lots of zeros (number of typos per word)
>- Families for ordinal (ordered) data [@burkner2019ordinal] (Likert scales)
>- **Log-Normal**: zero bound continuous data with positive skew
>- **Ex-Gaussian**: continuous data with positive skew [for key data: @chukharev2014pauses]


```{r eval=F, echo=T}
fit <- brm(outcome ~ predictor + (1|participant), data = data, family = exgaussian())
```



## Families of distributions (some important ones)

>- **Gaussian**: data are assumed to come from a normal distribution (last session)
>- **Bernoulli**: binomial data
>- **Poisson**: count data
>- **Zero-inflated Poisson**: count data with lots of zeros
>- Families for ordinal (ordered) data [@burkner2019ordinal]
>- **Log-Normal**: zero bound continuous data with positive skew
>- **Ex-Gaussian**: continuous data with positive skew [for key data: @chukharev2014pauses]
- Mixtures of distributions and distribution families [for key data: @almond2012preliminary; @roeser2020amlap; @roeser2021; @baaijen2012keystroke]

```{r eval=F, echo=T}
fit <- brm(outcome ~ predictor + (1|participant), data = data, family = mixture(gaussian(), gaussian()))
```




## Models of keystroke data


>- What is a good model of keystroke data?
>- For RT data there are many probability models: skewed Normal, shifted (log)-Normal, Wiener Diffusion models, ex-Gaussian etc. [see @matzke2009psychological].
>- Homework: 5 models of keystroke data (intercept only with random ppt intercepts):


## Models of keystroke data

<div style="float: left;width: 45%;">

- Keystroke data from 39 participants writing texts in their L1 (English) or L2 (Spanish).
- We will focus on sentence transitions (keystroke interval between sentences) because there is a lot happening before people start a sentence [cite me: @roeser2019advance].
- Skew is normal and contains important information.
- Different models entail different ways of thinking about skew.

</div>


<div style="float: right;width: 55%;">

```{r fig.width=5.5}
max <- 4500
data %>% filter(IKI < max) %>%
  mutate(Lang = recode(Lang, EN = "L1 (English)",
                             ES = "L2 (Spanish)"),
         transition_type = recode(transition_type, noedit = "no edit")) %>%
  ggplot(aes(x = Lang, y = IKI)) +
  geom_jitter(size = .1, width = .25, alpha = .35) +
#  geom_boxplot(outlier.colour = NA, width = .25,  position = position_dodge(.75)) +
  labs(colour = "Transition type", x = "Language", y = "IKI [in msecs]", caption = paste0("Trimmed at ", max, " msecs for visualisation")) 
```
</div>


## Gaussian

$$y \sim N(\mu, \sigma^2)$$

- Data generating process can be described as a normal distribution with mean $\mu$ and standard deviation $\sigma$.



## Log-Normal



```{r }
data$log_iki <- log(data$IKI)
iki <- ggplot(data, aes(x = IKI)) +
  geom_histogram() +
  labs(subtitle = "IKIs on msecs scale", x = "ikis")
log_iki <- ggplot(data, aes(x = log_iki)) +
  geom_histogram() +
  labs(subtitle = "IKIs on log-msecs scale", x = "log(ikis)")
iki + log_iki
```


## Log-Normal


$$
y \sim logN(\mu, \sigma^2)
$$

- Often used to address positive skew; e.g. response times [@baa08book]
- Log-values are only defined if $y \in [0, \infty]$
- De-emphasize large values over small values.
- Models the percentage change and not absolute differences:
  - Rather than saying "keystroke intervals are 40 msecs slower", you say "keystrokes are 7% slower". 
  - Difference of 40 msecs can be huge for fast typing but negligible for pauses around 10 secs. 






## Ex-Gaussian

<div style="float: left;width: 55%;">
>- Response is caused by a mix of two independent processes:
>  1. Gaussian distribution
>  2. Exponential distribution
  
- Parameters:
  - $\mu$: mean of the Gaussian; shorter/longer mean keystroke intervals
  - $\sigma$: standard deviation of the Gaussian; symmetrical variability around $\mu$
  - $\tau$: decay rate of the exponential; the tail of long keystroke intervals (higher $\tau$ means more tail dominance over the Gaussian)
</div>

<div style="float: right;width: 45%;">
![](pics/exgaus.png)
</div>


```{r}
exGausDist <- function(nObs = 10000, mu = 300, sd = 30, tau = 200) {
  round(rnorm(nObs, mu, sd) + rexp(nObs, 1 / tau))
}

exgaus <- tibble("t1" = exGausDist(tau = 50),
       "t2" = exGausDist(tau = 100),
       "t3" = exGausDist(tau = 250),
       "t4" = exGausDist(tau = 500)) %>%
  pivot_longer(everything())
```

## Ex-Gaussian

```{r}
exgaus %>% filter(name == "t1") %>%
  ggplot(aes(x = value, colour = name)) +
  geom_density(colour = "white") +
  scale_x_continuous(limits = c(0, 1500)) +
  scale_color_colorblind(breaks = paste0("t",1:4), labels = c(bquote(tau==50),bquote(tau==100),bquote(tau==250),bquote(tau==500))) +
  labs(colour = "Exponential\nparameter\nvalue", subtitle = bquote("Gaussian parameter values:"~mu==300*","~sigma==30), x = "x") +
  theme(legend.justification = "top")
```

## Ex-Gaussian

```{r}
exgaus %>% filter(name == "t1") %>%
  ggplot(aes(x = value, colour = name)) +
  geom_density() +
  scale_x_continuous(limits = c(0, 1500)) +
  scale_color_colorblind(breaks = paste0("t",1:4), labels = c(bquote(tau==50),bquote(tau==100),bquote(tau==250),bquote(tau==500))) +
  labs(colour = "Exponential\nparameter\nvalue", subtitle = bquote("Gaussian parameter values:"~mu==300*","~sigma==30), x = "x") +
  theme(legend.justification = "top")
```

## Ex-Gaussian

```{r}
exgaus %>% filter(name %in% paste0("t", 1:2)) %>%
  ggplot(aes(x = value, colour = name)) +
  geom_density() +
  scale_x_continuous(limits = c(0, 1500)) +
  scale_color_colorblind(breaks = paste0("t",1:4), labels = c(bquote(tau==50),bquote(tau==100),bquote(tau==250),bquote(tau==500))) +
  labs(colour = "Exponential\nparameter\nvalue", subtitle = bquote("Gaussian parameter values:"~mu==200*","~sigma==20), x = "x") +
  theme(legend.justification = "top")
```

## Ex-Gaussian

```{r}
exgaus %>% filter(name %in% paste0("t", 1:3)) %>%
  ggplot(aes(x = value, colour = name)) +
  geom_density() +
  scale_x_continuous(limits = c(0, 1500)) +
  scale_color_colorblind(breaks = paste0("t",1:4), labels = c(bquote(tau==50),bquote(tau==100),bquote(tau==250),bquote(tau==500))) +
  labs(colour = "Exponential\nparameter\nvalue", subtitle = bquote("Gaussian parameter values:"~mu==200*","~sigma==20), x = "x") +
  theme(legend.justification = "top")
```

## Ex-Gaussian

```{r}
exgaus %>% filter(name %in% paste0("t", 1:4)) %>%
  ggplot(aes(x = value, colour = name)) +
  geom_density() +
  scale_x_continuous(limits = c(0, 1500)) +
  scale_color_colorblind(breaks = paste0("t",1:4), labels = c(bquote(tau==50),bquote(tau==100),bquote(tau==250),bquote(tau==500))) +
  labs(colour = "Exponential\nparameter\nvalue", subtitle = bquote("Gaussian parameter values:"~mu==200*","~sigma==20), x = "x") +
  theme(legend.justification = "top")
```


## Ex-Gaussian

```{r echo = T, eval = F}

model <- bf(IKI ~ 1 + (1 | SubNo),  
            beta ~ 1 + (1 | SubNo), # decay parameter (exponential component)
            family = exgaussian())

prior <- set_prior("normal(250, 20)", class = "Intercept") +
         set_prior("normal(6, 2)", class = "Intercept", dpar = "beta") # decay rate in log msecs

```



## Skew-Normal

>- Gaussian with extra skew-parameter
>- Parameters: mean $\mu$, standard deviation $\sigma$ 
>- Skewness $\alpha$: Gaussian is $\alpha = 0$; positive skew $\alpha > 0$; negative skew $\alpha < 0$; 
  
  
```{r}
library(PearsonDS)

skewrnorm <- function(x = seq(-10, 10, .1), mean = 0, variance = 5, skewness = 0, kurtosis = 3){
  moments <- c(mean = mean, variance = variance, skewness = skewness, kurtosis = kurtosis)
  x <- dpearson(x, moments = moments)
  return(x)
}

tibble("t1" = skewrnorm(skewness = 0),
       "t2" = skewrnorm(skewness = .8),
       "t3" = skewrnorm(skewness = -.8),
       x = seq(-10, 10, .1)) %>%
  pivot_longer(-x) %>%
  group_by(name) %>%
  mutate(mean = mean(value),
         median = mean(value)) %>%
  ggplot(aes(x = x, y = value, colour = name)) +
  geom_line() +
  scale_x_continuous(limits = c(-10, 10)) +
  scale_color_colorblind(breaks = paste0("t",1:3), labels = c("No skew", "Right skew", "Left skew")) +
  labs(colour = "", subtitle = bquote("Gaussian parameter values:"~mu==0*","~sigma==5), x = "x", y = "density") +
  theme(legend.justification = "top") +
  geom_vline(xintercept = 0, linetype = "dotted") 


```


## Mixture model

$$
y \sim \theta \cdot N(\mu_1, \sigma_1) + (1-\theta) \cdot N(\mu_2, \sigma_2) 
$$

>- Finite mixture model with two mixture components with a straight forward interpretation
>- Keystroke intervals are a mix of two independent processes [@roeser2021]:
>- Short keystroke intervals: e.g. normal planning / execution
>- Long keystroke intervals: disfluent execution / planning

- Parameters:
  - $\mu_1, \sigma_1$: mean and sd of one distribution
  - $\mu_2, \sigma_2$: mean and sd of other distribution
  - $\theta$: mixing proportion of distributions

- Mixing proportion $\theta$ is the probability of *difficulty* in the sample (or condition).


```{r}
set.seed(100)
MixModDist <- function(n = 10000, mu = c(350, 750), sigma = c(50, 50), lambda = c(.5, .5)) {
  rnormmix(n = n, lambda = lambda, mu = mu, sigma = sigma)}

mixmod <- tibble("t1" = MixModDist(),
       "t2" = MixModDist(lambda = c(.6,.4)),
       "t3" = MixModDist(lambda = c(.75,.25)),
       "t4" = MixModDist(lambda = c(.95,.05))) %>%
  pivot_longer(everything())

```


## Mixture model

```{r}
mixmod %>% filter(name %in% paste0("t",1)) %>%
  ggplot(aes(x = value, colour = name)) +
 geom_density(colour = "white") +
 scale_x_continuous(limits = c(0, 1500)) +
 scale_color_colorblind(breaks = paste0("t",1:4), labels = c(bquote(theta[2]==.5),bquote(theta[2]==.4),bquote(theta[2]==.25),bquote(theta[2]==.05))) +
  labs(colour = "Mixing proportion\nparameter\nvalue", subtitle = bquote("Gaussian parameter values:"~mu[1]==350*","~mu[2]==750*","~sigma[1]==50*","~sigma[2]==50), x = "x") +
  theme(legend.justification = "top")
```

## Mixture model

```{r}
mixmod %>% filter(name %in% paste0("t",1)) %>%
  ggplot(aes(x = value, colour = name)) +
 geom_density() +
 scale_x_continuous(limits = c(0, 1500)) +
 scale_color_colorblind(breaks = paste0("t",1:4), labels = c(bquote(theta[2]==.5),bquote(theta[2]==.4),bquote(theta[2]==.25),bquote(theta[2]==.05))) +
  labs(colour = "Mixing proportion\nparameter\nvalue", subtitle = bquote("Gaussian parameter values:"~mu[1]==350*","~mu[2]==750*","~sigma[1]==50*","~sigma[2]==50), x = "x") +
  theme(legend.justification = "top")
```

## Mixture model

```{r}
mixmod %>% filter(name %in% paste0("t",1:2)) %>%
  ggplot(aes(x = value, colour = name)) +
 geom_density() +
 scale_x_continuous(limits = c(0, 1500)) +
 scale_color_colorblind(breaks = paste0("t",1:4), labels = c(bquote(theta[2]==.5),bquote(theta[2]==.4),bquote(theta[2]==.25),bquote(theta[2]==.05))) +
  labs(colour = "Mixing proportion\nparameter\nvalue", subtitle = bquote("Gaussian parameter values:"~mu[1]==350*","~mu[2]==750*","~sigma[1]==50*","~sigma[2]==50), x = "x") +
  theme(legend.justification = "top")
```


## Mixture model

```{r}
mixmod %>% filter(name %in% paste0("t",1:3)) %>%
  ggplot(aes(x = value, colour = name)) +
 geom_density() +
 scale_x_continuous(limits = c(0, 1500)) +
 scale_color_colorblind(breaks = paste0("t",1:4), labels = c(bquote(theta[2]==.5),bquote(theta[2]==.4),bquote(theta[2]==.25),bquote(theta[2]==.05))) +
  labs(colour = "Mixing proportion\nparameter\nvalue", subtitle = bquote("Gaussian parameter values:"~mu[1]==350*","~mu[2]==750*","~sigma[1]==50*","~sigma[2]==50), x = "x") +
  theme(legend.justification = "top")
```


## Mixture model


```{r echo = T, eval = F}
# Specify mixture model
mixture_of_lognormals <- mixture(lognormal(), lognormal(), order = TRUE)

# Specify model 
model <- bf(IKI ~ 1 + (1 | SubNo),
            theta2 ~ 1 + (1 | SubNo),
            family = mixture_of_lognormals)

# Setup priors
prior <-  set_prior("normal(4, 1)", class = "Intercept", dpar = "mu1") +
          set_prior("normal(6, 1)", class = "Intercept", dpar = "mu2") +
          set_prior("beta(2, 2)", class = "Intercept", dpar = "theta2") 
```



## Difference between models


Model             Extreme values
---------------   ------------------------------------------
Gaussian          Values follow normal distribution
log-Normal        Re-scale distance between adjacent values
skew-Normal       Skewness parameter
ex-Gaussian       Exponential component
Mixture model     Another (cognitive) process
    


## Exercise: model comparison (1)

- How well does the model predict the data?
- Draw data simulations from each model and compare them to the actual data.
- Complete the `---` bits of `visualise_model_fit.R` and run it line-by-line.
- This script assumes that you have stored the posterior of the five models from the homework: Gaussian, log-Normal, skew-Normal, ex-Gaussian, mixture model


## Model predictions

<div style="float: left;width: 65%;">

![](pics/modelcomps.png){width="94%"}

</div>

<div style="float: right;width: 30%;">

- Observed data $y$ compared to 100 simulations per model $y_{rep}$.
- *x*-axis cut off at 0 and 3k.
- Which model does the worst job; which does the best?

</div>


# Model comparisons | chapter 11 in @gelman2020regression; chapter 6 in @mcelreath2016statistical

## Model comparisons

>- What is a good account of reality for our data (keystroke intervals between sentences)?
>- How accurately does the model predict new data.
>- $R^2$ et al.: more complex models are generally better.
- **Overfitting:** models with too many parameters (e.g. predictors) make unreasonable predictions.
- That's because $R^2$ is based on the data that were used for model fit.
- Generalisations to data that were used to fit the model are over optimistic [@gelman2020regression].
- Instead, evaluating predictive performance of the model for new data.
  

## Leave-One-Out (LOO) cross validation

- Cross validation: performance of a model on **new** data to remove the overfitting problem.
- Split data into training set (for modelling) and validation set (for prediction).
- Leave-One-Out (LOO) Information Criterion (LOO-IC): 
  - Train model on $N-1$ observations 
  - Predict remaining data point from training model.
  - Repeat process $N$ times to predict every observation from a model of the remaining data.
- Adding up prediction results gives an estimate of **expected log-predictive density** ($elpd$); i.e. approximation of results that would be expected for new data.
- This would take forever; `loo()` function uses the probability calculations to approximate LOO-IC (i.e. Pareto smoothed importance sampling) [@vehtari2015pareto; @vehtari2017practical].




## Leave-One-Out (LOO) cross validation

<div style="float: left;width: 50%;">

>- Approximation involved in `loo()` uses the log posterior predictive densities: how likely is each data point given the distribution parameter estimates?

</div>


<div style="float: right;width: 50%;">

```{r fig.width=5}
log_lik(brms_sim) %>% 
  as_tibble() %>% mutate(sample = 1:n()) %>%
  pivot_longer(-sample, names_to = "obs", values_to = "loglik") %>%
  group_by(obs) %>%
  summarise(M = mean(loglik),
            var = var(loglik)) %>%
  mutate(obs = as.numeric(gsub(pattern = "V", replacement = "", obs))) %>%
  ggplot(aes(x = obs, y = M, ymin = M-var, ymax = M+var)) +
  geom_pointrange(fatten = .5) +
  labs(x = "Observations", y = "log-posterior predictive density (with variance)")
```

</div>


## Leave-One-Out (LOO) cross validation

<div style="float: left;width: 50%;">

```{r echo = T}
loo(brms_sim)
```


</div>

```{r}
# product of n factors one for each data point: with theta being all parameters
# for LOO CV we perform exclude each data point one at a time which is equivalent to multiplying posterior by factor 1/p(y_i \mid \theta)
# LOO posterior excluding i is p(\theta \ mid y_{-i}) = p(\theta \mid y) / p(y_i \mid \theta) using the the 
# LOO distribution uses the posterior simulatios for \theta and giving each simulation a weight of 1 / p(y_i \mid \theta)
# Weighted simulations is used to approximate the predictice distribution of y_i (the held-out data point)
# $$p(\theta \mid y) \propto p(\theta) \prod^n_{i=1} p(y_i \mid \theta)$$
```

```{r}
# pointwise density:
# Average likelihood of every observation in training sample
# this is done for each set of parameters sampled from the psoterior distribution
# Average liklihood for each obsersation
# Sum over all observations.
# resulting in the log-pointwise-predictive-density (lppd)

# effective number of parameters is the variance in log-likelihood for every observation: p_waic
# WAIC: -2*(lppd * p_waic)



```





<div style="float: right;width: 50%;">

```{r fig.width=5}
log_lik(brms_sim) %>% 
  as_tibble() %>% mutate(sample = 1:n()) %>%
  pivot_longer(-sample, names_to = "obs", values_to = "loglik") %>%
  group_by(obs) %>%
  summarise(M = mean(loglik),
            var = var(loglik)) %>%
  mutate(obs = as.numeric(gsub(pattern = "V", replacement = "", obs))) %>%
  ggplot(aes(x = obs, y = M, ymin = M-var, ymax = M+var)) +
  geom_pointrange(fatten = .5) +
  labs(x = "Observations", y = "log-posterior predictive density (with variance)")
```

</div>



## Leave-One-Out (LOO) cross validation

<div style="float: left;width: 50%;">

```{r echo = T}
loo(brms_sim)
```


>- `elpd_loo`: sum of means (expected log predictive density)
>- `p_loo`: sum of variances
>- `looic`: $-2 \cdot ($`elpd_loo`$-$`p_loo`$)$ (for deviance scale)


```{r echo = F}
loos <- log_lik(brms_sim) %>% as_tibble() %>% mutate(sample = 1:n()) %>%
  pivot_longer(-sample, names_to = "obs", values_to = "loglik") %>%
  group_by(obs) %>%
  summarise(mean_loglik = mean(exp(loglik)),
            var_loglik = var(loglik)) %>% 
  ungroup() %>%
  summarise(elpd_loo = sum(log(mean_loglik)), # sum of mean log lik
            p_loo = sum(var_loglik), # effective number of parameters
            looic = -2 * (elpd_loo - p_loo) # Bayesian deviance
            ) 
```


</div>

<div style="float: right;width: 50%;">

```{r fig.width=5}
log_lik(brms_sim) %>% 
  as_tibble() %>% mutate(sample = 1:n()) %>%
  pivot_longer(-sample, names_to = "obs", values_to = "loglik") %>%
  group_by(obs) %>%
  summarise(M = mean(loglik),
            var = var(loglik)) %>%
  mutate(obs = as.numeric(gsub(pattern = "V", replacement = "", obs))) %>%
  ggplot(aes(x = obs, y = M, ymin = M-var, ymax = M+var)) +
  geom_pointrange(fatten = .5) +
  labs(x = "Observations", y = "log-posterior predictive density (with variance)")
```

</div>


## Leave-One-Out (LOO) cross validation

<div style="float: left;width: 50%;">

```{r echo = T}
loo(brms_sim)
```



```{r}
#difference between two deviances has a chi-squared distribution; factor of 2 scales it that way; also called the Bayesian deviance


# N of parameters
# number of different conjectures for causes of explanations of the data
# How much iformation do we want the model to provide
# how flexible is themodel in fitting the training samples
# penalty term
# expected distance between in-sample and out-of-sample deviance
```

>- `elpd_loo` and `looic` rarely have a direct interpretation (as opposed to `loo_R2()`): important are differences between models.
>- `p_loo` is the effective number of parameters: how flexible is the model fit.



```{r echo = F}
loos <- log_lik(brms_sim) %>% as_tibble() %>% mutate(sample = 1:n()) %>%
  pivot_longer(-sample, names_to = "obs", values_to = "loglik") %>%
  group_by(obs) %>%
  summarise(mean_loglik = mean(exp(loglik)),
            var_loglik = var(loglik)) %>% 
  ungroup() %>%
  summarise(elpd_loo = sum(log(mean_loglik)), # sum of mean log lik
            p_loo = sum(var_loglik), # effective number of parameters
            looic = -2 * (elpd_loo - p_loo) # Bayesian deviance
            ) 
```


</div>

<div style="float: right;width: 50%;">

```{r fig.width=5}
log_lik(brms_sim) %>% 
  as_tibble() %>% mutate(sample = 1:n()) %>%
  pivot_longer(-sample, names_to = "obs", values_to = "loglik") %>%
  group_by(obs) %>%
  summarise(M = mean(loglik),
            var = var(loglik)) %>%
  mutate(obs = as.numeric(gsub(pattern = "V", replacement = "", obs))) %>%
  ggplot(aes(x = obs, y = M, ymin = M-var, ymax = M+var)) +
  geom_pointrange(fatten = .5) +
  labs(x = "Observations", y = "log-posterior predictive density (with variance)")
```

</div>


```{r}
#loo_R2(mixturemodel)
#bayes_R2(mixturemodel)

```




## Exercise: model comparison (2)

>- Open the script `model_comparison.R`
>- Complete the missing bits (`---`) and run the script.
>- Which model has the lowest elpd score (i.e. highest predictive performance)?
>- This script, again, assumes that you have stored the posterior of the 5 models from the homework: Gaussian, log-Normal, skew-Normal, ex-Gaussian, mixture model


```{r}
mc <- readRDS("../stanout/model_comparison.rda")
```


## Model comparison

```{r}
mc$diff %>%
  as.data.frame() %>%
  rownames_to_column("model") %>% 
  select(model:se_elpd_loo) %>%
  mutate(across(where(is.numeric), round, 1)) %>%
  kable() %>%
  kable_styling("striped", full_width = F) %>%
  column_spec(1:5, width = "10em") %>%
  add_footnote("`elpd_loo` is reported as $\\\\widehat{elpd}$ and the difference as $\\\\Delta\\\\widehat{elpd}$.")

```




## Mixture-model evaluation

>- Summarise the parameter estimates of the mixture model.
>- Complete the `---`s in `mixture_model_sentence_posterior.R` and run the script.
>- Try to make sense of the parameter estimates.


```{r}
mixturemodel <- readRDS("../stanout/mixture_model_sentence.rda")
```



## Mixture-model parameters (population level)

```{r echo = T, fig.height=3.75}
coefs <- c("b_mu1_Intercept", "b_mu2_Intercept", "b_theta2_Intercept")
mcmc_plot(mixturemodel, type = "hist", pars = coefs)
```

## Mixture-model parameters (population level)

```{r echo = T}
posterior_summary(mixturemodel, pars = "b_theta2_Intercept") %>% round(2)
```

```{r echo = T}
coefs <- c("b_mu1_Intercept", "b_mu2_Intercept")

posterior_samples(mixturemodel, pars = coefs) %>%
  pivot_longer(everything()) %>% mutate(value = exp(value)) %>%
  group_by(name) %>% summarise(mean = mean(value),
                               Q2.5 = quantile(value, .025),
                               Q97.5 = quantile(value, .975)) %>%
  mutate(across(where(is.numeric), round, 0))

```


## Mixture-model parameters (ppt level)

```{r fig.width=9}
ppt_vars <- posterior_summary(mixturemodel, pars = "r_SubNo__theta2") %>%
  as.data.frame() %>%
  rownames_to_column("SubNo") %>%
  mutate(SubNo = str_match(SubNo, "S-\\s*(.*?)\\s*[,]")[,1],
         SubNo = gsub(",", "", SubNo)) %>%
  as_tibble()

# Plot the by-ppt values
# Values above 0: ppt shows more long values than average
# Values below 0: ppt shows less long values than average
ggplot(ppt_vars, aes(y = Estimate, ymin = `Q2.5`, ymax = `Q97.5`, 
                     x = reorder(SubNo, Estimate))) +
  geom_hline(yintercept = 0, linetype = "dotted", colour = "grey") +
  geom_pointrange() + theme_bw() +
  labs(y = "Difference from population-level\nmixing proportion in SDs",
       x = "Participant id") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 10))
```



# The end

## Summary

- Priors aid parameter estimation.
- Bayes Factors allow us to compare hypotheses.
- `brms` allows us to fit various models of keystroke intervals: 
  - Mixture models showed better fit for sentence transitions.
- Estimate parameter other than expected keystroke latency:
  - Mixing proportion $\theta_2$ is an indicator of the probability to slow down after accounting for individual typing speed.
- Next: add slope coefficients to compare, e.g., whether L1 affects normal or slow typing or the probability of slowdowns.


## Recommended reading

>- Bürkner's tutorials [@brms1; @brms2; @burkner2019ordinal; @burkner2019bayesian]
>- Vasishth's tutorials [@sorensen2016bayesian; @nicenboim2016statistical; @vasishth2016statistical]
>- Book-length intros: @gelman2020regression, @mcelreath2016statistical, @kruschke2014doing, @lambert2018student, @lee2014bayesian


## References

<style>
slides > slide { overflow: scroll; }
slides > slide:not(.nobackground):after {
  content: '';
}
</style>

